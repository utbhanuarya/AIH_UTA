{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "RNtm1kuf-OhB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_jpaVhdQ--Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load relevant MIMIC-III data\n",
        "DATA_PATH = \"/content/\""
      ],
      "metadata": {
        "id": "qz3UBsYp_AZa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mimic_data():\n",
        "    admissions = pd.read_csv(os.path.join(DATA_PATH, 'ADMISSIONS.csv.gz'))\n",
        "    diagnoses = pd.read_csv(os.path.join(DATA_PATH, 'DIAGNOSES_ICD.csv.gz'))\n",
        "    labevents = pd.read_csv(os.path.join(DATA_PATH, 'LABEVENTS.csv.gz'))\n",
        "    return admissions, diagnoses, labevents"
      ],
      "metadata": {
        "id": "zj7Lx6cs_FP4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load relevant MIMIC-III data\n",
        "DATA_PATH = \"/content/\"\n",
        "admissions, diagnoses, labevents = load_mimic_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "j2YnwF6fBw0C",
        "outputId": "311a8e00-e9ee-4198-9a21-2c84c3b4fa57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Compressed file ended before the end-of-stream marker was reached",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1f79ed72fe34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load relevant MIMIC-III data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madmissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnoses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mimic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-31efbeb4f9a7>\u001b[0m in \u001b[0;36mload_mimic_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0madmissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADMISSIONS.csv.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdiagnoses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DIAGNOSES_ICD.csv.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LABEVENTS.csv.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madmissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnoses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabevents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    519\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_features(labevents):\n",
        "    top_items = labevents['ITEMID'].value_counts().nlargest(20).index.tolist()\n",
        "    filtered = labevents[labevents['ITEMID'].isin(top_items)]\n",
        "    pivot = filtered.pivot_table(\n",
        "        index='SUBJECT_ID',\n",
        "        columns='ITEMID',\n",
        "        values='VALUENUM',\n",
        "        aggfunc='mean'\n",
        "    ).fillna(0)\n",
        "    return pivot"
      ],
      "metadata": {
        "id": "nmAuK9iI_NSn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = preprocess_features(labevents).reset_index()"
      ],
      "metadata": {
        "id": "VvQONWHRB_hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract diagnosis code list per subject\n",
        "def get_diagnosis_labels(diagnoses):\n",
        "    grouped = diagnoses.groupby('SUBJECT_ID')['ICD9_CODE'].apply(list)\n",
        "    return grouped"
      ],
      "metadata": {
        "id": "8dKYQTYeAknf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_df = get_diagnosis_labels(diagnoses).reset_index()"
      ],
      "metadata": {
        "id": "y2C_kNx5CDdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge outcomes\n",
        "merged = pd.merge(features_df, admissions[['SUBJECT_ID', 'HOSPITAL_EXPIRE_FLAG', 'DISCHARGE_LOCATION']], on='SUBJECT_ID')\n",
        "merged = pd.merge(merged, diagnosis_df, on='SUBJECT_ID')"
      ],
      "metadata": {
        "id": "04YP7jM6CHgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = merged.drop(columns=['SUBJECT_ID', 'HOSPITAL_EXPIRE_FLAG', 'DISCHARGE_LOCATION', 'ICD9_CODE']).values\n",
        "y_mortality = merged['HOSPITAL_EXPIRE_FLAG'].values\n",
        "y_discharge = merged['DISCHARGE_LOCATION'].values\n",
        "y_diagnosis = merged['ICD9_CODE'].values"
      ],
      "metadata": {
        "id": "4CZOuVrSCM5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset class for contrastive learning\n",
        "class ContrastivePatientDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x1 = self.features[index]\n",
        "        x2 = self._augment(x1)\n",
        "        return torch.tensor(x1).float(), torch.tensor(x2).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def _augment(self, x):\n",
        "        noise = np.random.normal(0, 0.01, size=x.shape)\n",
        "        return x + noise\n",
        "\n",
        "# Encoder model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Contrastive Loss\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        z_i = nn.functional.normalize(z_i, dim=1)\n",
        "        z_j = nn.functional.normalize(z_j, dim=1)\n",
        "        logits = torch.matmul(z_i, z_j.T) / self.temperature\n",
        "        labels = torch.arange(len(z_i)).to(z_i.device)\n",
        "        return nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "# Train contrastive model\n",
        "def train_contrastive_model(data):\n",
        "    model = Encoder(input_dim=data.shape[1], hidden_dim=128)\n",
        "    loss_fn = ContrastiveLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    dataset = ContrastivePatientDataset(data)\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        for x1, x2 in loader:\n",
        "            z1 = model(x1)\n",
        "            z2 = model(x2)\n",
        "            loss = loss_fn(z1, z2)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "hGzigtZj_YMN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_contrastive_model(X)\n",
        "embeddings = model(torch.tensor(X).float()).detach().numpy()"
      ],
      "metadata": {
        "id": "98JfkveJCRyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mortality Prediction Task\n",
        "def mortality_prediction(embeddings, labels):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2)\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    proba = clf.predict_proba(X_test)[:, 1]\n",
        "    print(\"\\nMortality Prediction Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "    print(\"ROC AUC:\", roc_auc_score(y_test, proba))"
      ],
      "metadata": {
        "id": "lbtW0mwf_h_r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mortality_prediction(embeddings, y_mortality)"
      ],
      "metadata": {
        "id": "env8zVLSCXTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discharge Disposition Task\n",
        "def discharge_prediction(embeddings, dispositions):\n",
        "    le = LabelEncoder()\n",
        "    labels = le.fit_transform(dispositions)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2)\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    print(\"\\nDischarge Disposition Prediction Report:\")\n",
        "    print(classification_report(y_test, preds))"
      ],
      "metadata": {
        "id": "3D0PT1x3_kGH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discharge_prediction(embeddings, y_discharge)"
      ],
      "metadata": {
        "id": "Hj9w8Y7lCYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnosis Code Prediction Task (multi-label)\n",
        "def diagnosis_prediction(embeddings, diagnosis_codes):\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    Y = mlb.fit_transform(diagnosis_codes)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, Y, test_size=0.2)\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    print(\"\\nDiagnosis Code Prediction F1 (Micro):\", f1_score(y_test, preds, average='micro'))\n"
      ],
      "metadata": {
        "id": "7344UTGo_lyN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_prediction(embeddings, y_diagnosis)"
      ],
      "metadata": {
        "id": "9RYF_F_3Cc9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE Visualization\n",
        "def visualize_embeddings(embeddings, labels, title=\"t-SNE Visualization\"):\n",
        "    tsne = TSNE(n_components=2)\n",
        "    reduced = tsne.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ug2XUX7h_sxe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_embeddings(embeddings, y_mortality, title=\"t-SNE of Contrastive Embeddings (Mortality)\")"
      ],
      "metadata": {
        "id": "blq9gAXlCfol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7KpZ7NdBlBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}